{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch as tc\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_augm = 0.05 #0.5\n",
    "#add rotate.  less p_augm\n",
    "\n",
    "class CFG:\n",
    "    # ============== pred target =============\n",
    "    target_size = 1\n",
    "\n",
    "    # ============== model CFG =============\n",
    "    model_name = 'Unet'\n",
    "    backbone = 'resnext50_32x4d'\n",
    "\n",
    "    in_chans = 1   #5 # 65\n",
    "    # ============== training CFG =============\n",
    "    image_size = 1024 # 512 # 512\n",
    "    input_size = 1024 # 512 #=512\n",
    "\n",
    "    train_batch_size = 4 #4 #16\n",
    "    valid_batch_size = 4\n",
    "\n",
    "    epochs = 31 #30 #25\n",
    "    lr = 8e-5\n",
    "    chopping_percentile=1e-3\n",
    "    # ============== fold =============\n",
    "    valid_id = 1\n",
    "\n",
    "\n",
    "    # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        A.Rotate(limit=270, p= 0.5),\n",
    "        A.RandomScale(scale_limit=(0.8,1.25),interpolation=cv2.INTER_CUBIC,p=p_augm),\n",
    "        A.RandomCrop(input_size, input_size,p=1),\n",
    "        A.RandomGamma(p=p_augm*2/3),\n",
    "        A.RandomBrightnessContrast(p=p_augm,),\n",
    "        A.GaussianBlur(p=p_augm),\n",
    "        A.MotionBlur(p=p_augm),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=p_augm),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    train_aug = A.Compose(train_aug_list)\n",
    "    valid_aug_list = [\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    valid_aug = A.Compose(valid_aug_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1024(img , image_size = 1024):\n",
    "    if image_size > img.shape[1]:\n",
    "       img = np.rot90(img)\n",
    "       start1 = (CFG.image_size - img.shape[0])//2 \n",
    "       top =     img[0                    : start1,   0: img.shape[1] ]\n",
    "       bottom  = img[img.shape[0] -start1 : img.shape[0],   0 : img.shape[1] ]\n",
    "       img_result = np.concatenate((top,img,bottom ),axis=0)\n",
    "       img_result = np.rot90(img_result)\n",
    "       img_result = np.rot90(img_result)\n",
    "       img_result = np.rot90(img_result)\n",
    "    else :\n",
    "       img_result = img\n",
    "    return img_result\n",
    "\n",
    "#  add border\n",
    "def to_1024_1024(img  , image_size = 1024 ):\n",
    "     img_result = to_1024(img, image_size )\n",
    "     return img_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class Data_loader(Dataset):\n",
    "     \n",
    "    def __init__(self,paths,is_label):\n",
    "        self.paths=paths\n",
    "        self.paths.sort()\n",
    "        self.is_label=is_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "         \n",
    "        img = cv2.imread(self.paths[index],cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = to_1024_1024(img , image_size = CFG.image_size ) #  to_original( im_after, img_save, image_size = 1024)\n",
    "\n",
    "        img = tc.from_numpy(img.copy())\n",
    "        if self.is_label:\n",
    "            img=(img!=0).to(tc.uint8)*255\n",
    "        else:\n",
    "            img=img.to(tc.uint8)\n",
    "        return img'''\n",
    "\n",
    "class Data_loader(Dataset):\n",
    "    def __init__(self,path,s=\"/images/\"):\n",
    "        self.paths=glob(path+f\"{s}*.tif\")\n",
    "        self.paths.sort()\n",
    "        self.bool=s==\"/labels/\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img=cv2.imread(self.paths[index],cv2.IMREAD_GRAYSCALE)\n",
    "        img = to_1024_1024(img , image_size = CFG.image_size )\n",
    "        \n",
    "        img=tc.from_numpy(img.copy())\n",
    "        if self.bool:\n",
    "            img=img.to(tc.bool)\n",
    "        else:\n",
    "            img=img.to(tc.uint8)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load('src/util/2d_nn/2d_segmentation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2217, 1041, 1511)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_i = 0 \n",
    "class CFG_Load:\n",
    "    model_name = 'Unet'\n",
    "    backbone = 'resnext50_32x4d'\n",
    "\n",
    "    in_chans = 1\n",
    "    image_size = 1024 \n",
    "    input_size= 1024\n",
    "    tile_size = image_size\n",
    "    stride = tile_size // 4\n",
    "    drop_egde_pixel= 0 \n",
    "    \n",
    "    target_size = 1\n",
    "    chopping_percentile=1e-3\n",
    "    valid_id = 1\n",
    "    batch=16 \n",
    "    th_percentile = 0.00143\n",
    "    \n",
    "    path_submition = 0 \n",
    "    model_path=[\"/root/sennet-kaggle/src/util/2d_nn/resnext50_32x4d_21_loss0.06_score0.87_val_loss0.21_val_score0.81_midd_1024.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,s):\n",
    "    data_loader=Data_loader(path,s)\n",
    "    data_loader=DataLoader(data_loader, batch_size=16, num_workers=2)\n",
    "    data=[]\n",
    "    for x in tqdm(data_loader):\n",
    "        data.append(x)\n",
    "    x=tc.cat(data,dim=0)\n",
    "    ########################################################################\n",
    "    TH=x.reshape(-1).numpy()\n",
    "    index = -int(len(TH) * CFG.chopping_percentile)\n",
    "    TH:int = np.partition(TH, index)[index]\n",
    "    x[x>TH]=int(TH)\n",
    "    ########################################################################\n",
    "    TH=x.reshape(-1).numpy()\n",
    "    index = -int(len(TH) * CFG.chopping_percentile)\n",
    "    TH:int = np.partition(TH, -index)[-index]\n",
    "    x[x<TH]=int(TH)\n",
    "    ########################################################################\n",
    "    #x=(min_max_normalization(x.to(tc.float16))*255).to(tc.uint8)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline_Dataset(Dataset):\n",
    "    def __init__(self,x,path):\n",
    "        self.img_paths  = glob(path+\"/images/*\")\n",
    "        self.img_paths.sort()\n",
    "        self.in_chan = CFG_Load.in_chans\n",
    "        z=tc.zeros(self.in_chan//2,*x.shape[1:],dtype=x.dtype)\n",
    "        self.x=tc.cat((z,x,z),dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]-self.in_chan+1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x  = self.x[index:index+self.in_chan]\n",
    "        return x,index\n",
    "    \n",
    "    def get_mark(self,index):\n",
    "        id=self.img_paths[index].split(\"/\")[-3:]\n",
    "        id.pop(1)\n",
    "        id=\"_\".join(id)\n",
    "        return id[:-4]\n",
    "    \n",
    "    def get_marks(self):\n",
    "        ids=[]\n",
    "        for index in range(len(self)):\n",
    "            ids.append(self.get_mark(index))\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_np = np.split(mask, 1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2217, 1041, 1511)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(debug=False):\n",
    "    outputs=[]\n",
    "    paths=[\"/root/data/train/kidney_2\"]\n",
    "    outputs=([],[])\n",
    "    for i in range(mask.shape[0]):\n",
    "        outputs[0].append(mask[i,:,:])\n",
    "    for path in [paths[CFG_Load.path_submition]]:\n",
    "        x=load_data(path,\"/images/\")\n",
    "        mark=Pipeline_Dataset(x,path).get_marks()\n",
    "        outputs[1].extend(mark)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redone\n",
    "def get_output(debug=False):\n",
    "    outputs=[]\n",
    "    paths=[\"/root/data/train/kidney_2\"]\n",
    "    outputs=[[],[]]\n",
    "    for arr in split_np:\n",
    "        labels=tc.zeros_like(x,dtype=tc.uint8)\n",
    "        outputs[0].append(arr)\n",
    "    for path in [paths[CFG_Load.path_submition]]:\n",
    "        x=load_data(path,\"/images/\")\n",
    "        mark=Pipeline_Dataset(x,path).get_marks()\n",
    "        outputs[1].extend(mark)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:04<00:00, 30.54it/s]\n"
     ]
    }
   ],
   "source": [
    "output, ids = get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixel = mask.flatten()\n",
    "    pixel = np.concatenate([[0], pixel, [0]])\n",
    "    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n",
    "    run[1::2] -= run[::2]\n",
    "    rle = ' '.join(str(r) for r in run)\n",
    "    if rle == '':\n",
    "        rle = '1 0'\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_original ( im_after, img, image_size = 1024 ):\n",
    "    top_ = 0\n",
    "    left_ = 0\n",
    "    if (im_after.shape[0] > img.shape[0]):\n",
    "             top_  = ( image_size - img.shape[0])//2 \n",
    "    if    (im_after.shape[1] > img.shape[1]) :\n",
    "             left_  = ( image_size - img.shape[1])//2  \n",
    "    if (top_>0)or (left_>0) :\n",
    "             img_result = im_after[top_  : img.shape[0] + top_,   left_: img.shape[1] + left_ ]\n",
    "    else:\n",
    "             img_result = im_after\n",
    "    return img_result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (12,) (13,) (12,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     mask_pred2 \u001b[38;5;241m=\u001b[39m to_original(mask_pred, img, image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     17\u001b[0m     mask_pred \u001b[38;5;241m=\u001b[39m mask_pred2\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 19\u001b[0m     rle \u001b[38;5;241m=\u001b[39m \u001b[43mrle_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     submission_df\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     22\u001b[0m         pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrle\u001b[39m\u001b[38;5;124m'\u001b[39m : rle,\n\u001b[1;32m     25\u001b[0m         },index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     28\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(submission_df)\n",
      "Cell \u001b[0;32mIn[171], line 5\u001b[0m, in \u001b[0;36mrle_encode\u001b[0;34m(mask)\u001b[0m\n\u001b[1;32m      3\u001b[0m pixel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([[\u001b[38;5;241m0\u001b[39m], pixel, [\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m      4\u001b[0m run \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(pixel[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m pixel[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m run[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m run[::\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      6\u001b[0m rle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m run)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (12,) (13,) (12,) "
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"/root/data/train/kidney_2/images/0000.tif\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "submission_df = []\n",
    "\n",
    "for index in range(len(ids)):\n",
    "    id=ids[index]\n",
    "    i=0\n",
    "    for x in output:\n",
    "        if index>=len(x):\n",
    "            index-=len(x)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    mask_pred = (output[0])\n",
    "\n",
    "    mask_pred2 = to_original(mask_pred, img, image_size=1024)\n",
    "    mask_pred = mask_pred2.copy()\n",
    "\n",
    "    rle = rle_encode(mask_pred)\n",
    "\n",
    "    submission_df.append(\n",
    "        pd.DataFrame(data={\n",
    "            'id' : id,\n",
    "            'rle' : rle,\n",
    "        },index=[0])\n",
    "    )\n",
    "\n",
    "submission_df = pd.concat(submission_df)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
