{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "log_board = util.diagnostics.LogBoard('log_dir', 6005)\n",
    "log_board.launch()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /train/kidney_1_dense/images from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0116 06:36:37.304590 140395134047424 program.py:298] TensorBoard could not bind to port 6005, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6005, it was already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /train/kidney_1_dense/labels from cache\n",
      "Loading /train/kidney_3_sparse/images from cache\n",
      "Loading /train/kidney_3_sparse/labels from cache\n",
      "Loading /train/kidney_2/images from cache\n",
      "Loading /train/kidney_2/labels from cache\n"
     ]
    }
   ],
   "source": [
    "patch_size = 64\n",
    "train = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=1.0,\n",
    "    samples=[\n",
    "        \"/train/kidney_1_dense\",\n",
    "        \"/train/kidney_3_sparse\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "test = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=1.0,\n",
    "    samples=[\n",
    "        \"/train/kidney_2\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_board.clear('train')\n",
    "log_board.clear('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "save_every = 1000\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "t_logger = log_board.get_logger('train')\n",
    "v_logger = log_board.get_logger('val')\n",
    "\n",
    "train_data = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_data = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = util.UNet3D(\n",
    "    layers=[16, 32, 64, 128, 16],\n",
    "    Conv3d=util.nn.Conv3DNormed,\n",
    "    block_depth=4,\n",
    "    connect_depth=8,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "# model.load_state_dict(torch.load('./bin/models/unet3d.pt', map_location=device))\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "dice_fn = util.DiceScore().to(device)\n",
    "focal_loss = util.BinaryFocalLoss(\n",
    "    alpha=0.5,\n",
    "    gamma=1.5,\n",
    ")\n",
    "\n",
    "t = time()\n",
    "step = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (x, y, _) in enumerate(train_data):\n",
    "        step += 1\n",
    "\n",
    "        # Prepare data\n",
    "        aug = util.PatchAugment().to(device)\n",
    "        x, y = aug(x.float().to(device)), aug(y.float().to(device))\n",
    "\n",
    "        # Compute output\n",
    "        logits = model(x)\n",
    "        p_y = [torch.sigmoid(logit) for logit in logits]\n",
    "        pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "        masks = model.deep_masks(y)[1:]\n",
    "\n",
    "        # Compute loss\n",
    "        dlayers = [0,1,2,3]\n",
    "        flyaers = [0]\n",
    "        dloss = torch.stack([\n",
    "            (1 - dice_fn(p_y[i], masks[i]))\n",
    "            for i in dlayers\n",
    "        ])\n",
    "        floss = torch.stack([\n",
    "            focal_loss(p_y[i], masks[i])\n",
    "            for i in flyaers\n",
    "        ])\n",
    "        loss = dloss.sum() + floss.sum()\n",
    "\n",
    "        # Step grad\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Logging & validation\n",
    "        with torch.no_grad():\n",
    "            # log loss\n",
    "            loss_dict = { f'dice_{k}' : dloss[i] for i, k in enumerate(dlayers) }\n",
    "            loss_dict.update({ f'focal_{k}' : floss[i] for i, k in enumerate(flyaers) })\n",
    "            t_logger.add_scalars('loss', loss_dict, step)\n",
    "            \n",
    "            # performance\n",
    "            acc = [torch.eq(pred_masks[i], masks[i]).float().mean() for i in dlayers]\n",
    "            dice = [dice_fn(pred_masks[i], masks[i]) for i in dlayers]\n",
    "            perf_dict = { f'acc_{k}' : acc[i] for i, k in enumerate(dlayers) }\n",
    "            perf_dict.update({ f'dice_{k}' : dice[i] for i, k in enumerate(dlayers) })\n",
    "            t_logger.add_scalars('performance', perf_dict, step)\n",
    "\n",
    "            # stats\n",
    "            for i, (prob, pred, mask) in enumerate(zip(p_y[1:], pred_masks[1:], masks[1:])):\n",
    "                t_logger.add_scalars(f'stats_{i + 1}',{\n",
    "                    'prob_std': prob.std(),\n",
    "                    'prob_mean': prob.mean(),\n",
    "                    'pred_std': pred.std(),\n",
    "                    'pred_mean': pred.mean(),\n",
    "                    'mask_std': mask.std(),\n",
    "                    'mask_mean': mask.mean(),\n",
    "                }, step)\n",
    "\n",
    "            # Validation logging\n",
    "            if (step + 1) % 150 == 0:\n",
    "                model.eval()\n",
    "                x, y, _ = next(iter(valid_data))\n",
    "                x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "                # Compute output\n",
    "                logits = model(x)\n",
    "                p_y = [torch.sigmoid(logit) for logit in logits]\n",
    "                pred_masks = [p > 0.5 for p in p_y]\n",
    "                masks = model.deep_masks(y)[1:]\n",
    "\n",
    "                acc = [torch.eq(pred_masks[i], masks[i]).float().mean() for i in dlayers]\n",
    "                dice = [dice_fn(pred_masks[i], masks[i]) for i in dlayers]\n",
    "                perf_dict = { f'acc_{k}' : acc[i] for i, k in enumerate(dlayers) }\n",
    "                perf_dict.update({ f'dice_{k}' : dice[i] for i, k in enumerate(dlayers) })\n",
    "                v_logger.add_scalars('performance', perf_dict, step)\n",
    "\n",
    "                v_logger.add_image('masks', util.mask_plots(x, masks, pred_masks), step, dataformats='HWC')\n",
    "                t_logger.add_scalar('time', time() - t, step)\n",
    "                t = time()\n",
    "                model.train()\n",
    "                \n",
    "            # Save model\n",
    "            if (step + 1) % save_every == 0:\n",
    "                torch.save(model.state_dict(), f'./bin/_tmp_models/unet_IN_PROGRESS.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('./bin/models', exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), f'./bin/models/unet3d2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(32, 1, 16, 16, 16)\n",
    "x.amax((2,3,4)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
