{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /train/kidney_2/images from cache\n",
      "Loading /train/kidney_2/labels from cache\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import util\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fine_patcher = util.UNet3D(\n",
    "    layers=[16, 32, 64, 128, 16],\n",
    "    Conv3d=util.nn.Conv3DNormed,\n",
    "    block_depth=4,\n",
    "    connect_depth=8,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "fine_patcher.load_state_dict(torch.load('./bin/models/unet3d.pt', map_location=device))\n",
    "fine_patcher.requires_grad_(False)\n",
    "fine_patcher.eval()\n",
    "\n",
    "coarse_patcher = util.UNet3D(\n",
    "    layers=[16, 32, 64, 64, 128, 128, 256],\n",
    "    Conv3d=util.nn.Conv3DNormed,\n",
    "    block_depth=8,\n",
    "    connect_depth=4,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "coarse_patcher.load_state_dict(torch.load('./bin/_tmp_models/wide_patcher_finder_IN_PROGRESS.pt', map_location=device))\n",
    "coarse_patcher.requires_grad_(False)\n",
    "coarse_patcher.eval()\n",
    "\n",
    "patch_size = 64\n",
    "chunk_size = 16\n",
    "nchunks = patch_size // chunk_size\n",
    "train = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=0.5,\n",
    "    samples=[\n",
    "        # \"/train/kidney_1_dense\",\n",
    "        # \"/train/kidney_3_sparse\",\n",
    "        \"/train/kidney_2\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e8d82eba324946b286ec8187860b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference = util.ScanInferece(\n",
    "    coarse_patcher,\n",
    "    fine_patcher,\n",
    "    batch_size=128,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    out_mask = inference(train.scans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('/root/data/model_outputs', exist_ok=True)\n",
    "\n",
    "torch.save(out_mask, '/root/data/model_outputs/kidney_2_3dmask.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_2d = torch.load(\"./bin/output/2d_segmentation.pt\").unsqueeze(0) > 75\n",
    "full_msk = torch.clamp(msk_2d + out_mask, 0, 1)\n",
    "\n",
    "torch.save(full_msk, '/root/data/output/combined_msk.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './bin/output/kidney_2_3dmask.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_msk \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./bin/output/kidney_2_3dmask.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m util\u001b[38;5;241m.\u001b[39mDiceScore()(full_msk, train\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './bin/output/kidney_2_3dmask.pt'"
     ]
    }
   ],
   "source": [
    "full_msk = torch.load('/root/data/output/kidney_2_3dmask.pt')\n",
    "util.DiceScore()(full_msk, train.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_msk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m util\u001b[38;5;241m.\u001b[39mDisplay(\u001b[43mfull_msk\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze())(), util\u001b[38;5;241m.\u001b[39mDisplay(train\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze())()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_msk' is not defined"
     ]
    }
   ],
   "source": [
    "util.Display(full_msk.squeeze())(), util.Display(train.labels[0].squeeze())()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from util import SweepCube\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class FilterNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # assert len(layers) >= 2, \"layers must have at least 2 elements\"\n",
    "\n",
    "        kernel_size = 9\n",
    "        layers = [2, 2, 2, 2, 2,2,2,2, 3]\n",
    "\n",
    "        c = layers[0]\n",
    "        # L = []\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i, l in enumerate(layers[1:-1]):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                util.FFTConv3d(c, l, kernel_size),\n",
    "                torch.nn.GELU(),\n",
    "            ))\n",
    "            c = l\n",
    "        self.layers.append(\n",
    "            util.FFTConv3d(c, layers[-1], kernel_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.layers[0](x)\n",
    "        for layer in self.layers[1:]:\n",
    "            z = layer(z)\n",
    "        return z\n",
    "\n",
    "class ProcessScan(nn.Module):\n",
    "    def __init__(self, patching_fn: Callable[[torch.Tensor], torch.Tensor], in_patch_size: int, out_patch_size: int, batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        assert in_patch_size % out_patch_size == 0, \"in_patch_size must be a multiple of out_patch_size\"\n",
    "\n",
    "        self.patcher = patching_fn\n",
    "        self.in_patch_size = in_patch_size\n",
    "        self.out_patch_size = out_patch_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor, working_device: str = \"cuda\") -> torch.Tensor:\n",
    "        agg_pred = torch.zeros_like(x)\n",
    "        scan_loader = DataLoader(\n",
    "            SweepCube(x, self.in_patch_size, self.out_patch_size),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "    \n",
    "        for xs, positions in tqdm(scan_loader):\n",
    "            xs = xs.to(working_device).float()\n",
    "            pred_mask = self.patcher(xs)\n",
    "\n",
    "            for p, pos in zip(pred_mask.cpu(), positions):\n",
    "                agg_pred[\n",
    "                    :,\n",
    "                    pos[0]:pos[0] + self.coarse_patch_size,\n",
    "                    pos[1]:pos[1] + self.coarse_patch_size,\n",
    "                    pos[2]:pos[2] + self.coarse_patch_size,\n",
    "                ] = p\n",
    "        \n",
    "        return agg_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7861, device='cuda:0')\n",
      "tensor([[    0,    17,   166,   280,     1,   858,   380,   579],\n",
      "        [    1,    76,     2,   234,     0,   200,  1296,   734],\n",
      "        [    2,     0,     0,     0,     0,   874,    98,   890],\n",
      "        [    3,   269,    94,  2868,    11,   247,   758,   994],\n",
      "        [    4,  7345,   939, 10840,    44,   600,   712,   700],\n",
      "        [    5,    47,    60,     5,     0,   692,   619,   353],\n",
      "        [    6,   475,   551,  4229,    18,   194,   688,   571],\n",
      "        [    7,     0,     0,     0,     0,   447,   987,   375],\n",
      "        [    8,     0,     0,     0,     0,   718,   595,   104],\n",
      "        [    9,     0,     0,     0,     0,   814,  1307,   725]],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def to_chunks(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.unfold(2, chunk_size, chunk_size) \\\n",
    "        .unfold(3, chunk_size, chunk_size) \\\n",
    "        .unfold(4, chunk_size, chunk_size)\n",
    "        # .reshape(-1, 1, chunk_size, chunk_size, chunk_size)\n",
    "\n",
    "def assemble_patch(x : torch.Tensor) -> torch.Tensor:\n",
    "    return x.reshape(batch_size, nchunks, nchunks, nchunks, 1, chunk_size, chunk_size, chunk_size) \\\n",
    "        .permute(0, 4, 1, 5, 2, 6, 3, 7) \\\n",
    "        .reshape(batch_size, 1, patch_size, patch_size, patch_size)\n",
    "\n",
    "dice_fn = util.DiceScore().to(device)\n",
    "\n",
    "batch_size = 10\n",
    "train_data = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Coarse patcher prediction\n",
    "x, y, pos = next(iter(train_data))\n",
    "x, y = x.to(device).float(), y.to(device).float()\n",
    "\n",
    "# cutoff_density = 0.1\n",
    "# y_filter = y.mean(dim=(1, 2, 3, 4)) < cutoff_density\n",
    "# x, y = x[y_filter], y[y_filter]\n",
    "\n",
    "p_y = [F.sigmoid(logits) for logits in coarse_patcher(x, up_depth=2)]\n",
    "pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "masks = coarse_patcher.deep_masks(y)[1:3]\n",
    "acc = [torch.eq(pred_masks[i], masks[i]).float().mean() for i in range(len(pred_masks))]\n",
    "dice = [dice_fn(pred_masks[i], masks[i]) for i in range(len(pred_masks))]\n",
    "\n",
    "# Filter fine patcher input\n",
    "fine_input = to_chunks(x)[pred_masks[-1].bool()].unsqueeze(1)\n",
    "\n",
    "# Fine patcher prediction\n",
    "p_y_fine = [F.sigmoid(logits) for logits in fine_patcher(fine_input)]\n",
    "pred_masks_fine = [(p > 0.5).float() for p in p_y_fine]\n",
    "masks_fine = fine_patcher.deep_masks(y)[1:]\n",
    "\n",
    "# Stitch fine patches together\n",
    "full_pred = torch.zeros_like(y)\n",
    "to_chunks(full_pred)[pred_masks[-1].bool()] = pred_masks_fine[-1].squeeze(1)\n",
    "\n",
    "\n",
    "# Logging\n",
    "print(dice_fn(full_pred, y))\n",
    "def fp(pred, true):\n",
    "    true_positives = (pred * true).sum()\n",
    "    false_positives = (pred * (1 - true)).sum()\n",
    "    false_negatives = ((1 - pred) * true).sum()\n",
    "    return torch.stack([false_positives, false_negatives, true_positives, true.mean() * 1000])\n",
    "\n",
    "print(torch.stack([torch.cat([torch.tensor([i], device=device), fp(p, t), pos[i].to(device)]).int() for i,(p, t) in enumerate(zip(full_pred, y))]))\n",
    "print(len(full_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0449, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaa49fe121742e687dee5561fdffed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05401ea545434707b9134c818a6f907a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_density = 0.1 # 0.5 ?\n",
    "\n",
    "i = 4\n",
    "print(y[i].mean())\n",
    "util.Display(full_pred[i].squeeze().cpu())(), util.Display(x[i].squeeze().cpu(), y[i].squeeze().cpu())()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=0.5,\n",
    "    samples=[\n",
    "        # \"/train/kidney_1_dense\",\n",
    "        # \"/train/kidney_3_sparse\",\n",
    "        \"/train/kidney_2\",\n",
    "    ],\n",
    "    data_dir = \"../../data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65c8f3e10b44364b07e1fa24e99b504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=1510), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "util.Display(train.labels[0].squeeze())()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns = 1000\n",
    "\n",
    "class AggDice(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.agg_intersection = 0\n",
    "        # self.agg_cardinality = 0\n",
    "\n",
    "        self.true_positives = 0\n",
    "        self.false_positives = 0\n",
    "        self.false_negatives = 0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # self.agg_intersection += (y_pred * y_true).sum()\n",
    "        # self.agg_cardinality += (y_pred + y_true).sum()\n",
    "        # return 2 * self.agg_intersection / self.agg_cardinality\n",
    "\n",
    "        self.true_positives += (y_pred * y_true).sum()\n",
    "        self.false_positives += (y_pred * (1 - y_true)).sum()\n",
    "        self.false_negatives += ((1 - y_pred) * y_true).sum()\n",
    "\n",
    "        return 2 * self.true_positives / (2 * self.true_positives + self.false_positives + self.false_negatives)\n",
    "\n",
    "dice_fn = AggDice()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(nruns):\n",
    "        x, y, _ = next(iter(valid_data))\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "        # Compute output\n",
    "        p_y = fine_patcher(x, threshold=0.51)\n",
    "        # p_y[-1] += p_y[-1] * F.interpolate(p_y[-2] - 0.5, size=16, mode='nearest') * 0.5\n",
    "        # p_y[-1] += F.interpolate(p_y[-3] - 0.5, size=16, mode='nearest') * 0.1\n",
    "        pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "        masks = fine_patcher.unet.deep_masks(y)\n",
    "\n",
    "        # p_y[-1] -= F.interpolate(((p_y[-2]) < 0.5).float() - 0.5, size=16, mode='nearest') * 0.1\n",
    "        p_y[-1] -= F.interpolate((p_y[-2] < 0.1).float(), size=16, mode='nearest') * \\\n",
    "             F.interpolate((p_y[-3] < 0.1).float(), size=16, mode='nearest') * \\\n",
    "            F.interpolate((p_y[-4] < 0.1).float(), size=16, mode='nearest') * 0.01\n",
    "        p_y[-1] += F.interpolate((p_y[-2] > 0.5).float(), size=16, mode='nearest') * \\\n",
    "             F.interpolate((p_y[-3] > 0.5).float(), size=16, mode='nearest') * \\\n",
    "            F.interpolate((p_y[-4] > 0.5).float(), size=16, mode='nearest') * 0.01\n",
    "        # p_y[-1] -= F.interpolate((p_y[-4] < 0.5).float(), size=16, mode='nearest') * 0.01\n",
    "\n",
    "        pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Dice: ', dice_fn(pred_masks[-1], masks[-1]).item())\n",
    "            print('true_positives: ', dice_fn.true_positives)# / (i + 1))\n",
    "            print('false_positives: ', dice_fn.false_positives)# / (i + 1))\n",
    "            print('false_negatives: ', dice_fn.false_negatives)# / (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8576, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40710f3c3ab04616b545a8fe74935280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691b87defc314ef380af5bbb22b3c1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to_chunks(x)[pred_masks[-1].bool()].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([275, 1, 16, 16, 16])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_masks_fine[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = assemble_patch(x)\n",
    "y = assemble_patch(y)\n",
    "pred_masks = assemble_patch(pred_masks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8498, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_fn(full_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd949295b6245fd9a5a27a4ad157d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821375f57ad04ff8b17094bf1e0af305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0114 22:45:24.482801 140600046679232 program.py:298] TensorBoard could not bind to port 6005, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6005, it was already in use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patcher(\n",
       "  (unet): UNet3D(\n",
       "    (input_norm): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-7): 7 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-7): 7 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-7): 7 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-7): 7 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-7): 7 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cross_blocks): ModuleList(\n",
       "      (0): UNetCrossBlock3D(\n",
       "        (resize_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0-7): 8 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Upsample(scale_factor=4.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=8.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Upsample(scale_factor=16.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(1024, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (full_conv_block): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0-7): 8 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): UNetCrossBlock3D(\n",
       "        (resize_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0-7): 8 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=4.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Upsample(scale_factor=8.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(1024, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (full_conv_block): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0-7): 8 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): UNetCrossBlock3D(\n",
       "        (resize_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): MaxPool3d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=True)\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0-7): 8 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Upsample(scale_factor=4.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(1024, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (full_conv_block): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0-7): 8 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UNetCrossBlock3D(\n",
       "        (resize_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): MaxPool3d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=True)\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0-7): 8 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): MaxPool3d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=True)\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(512, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode='trilinear')\n",
       "            (1): ConvBlock(\n",
       "              (layers): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(1024, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "                (1-7): 7 x Sequential(\n",
       "                  (0): Dropout3d(p=0.2, inplace=False)\n",
       "                  (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                  (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (full_conv_block): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0-7): 8 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "              (2): BatchNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv3DNormed(1024, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1-3): 3 x Sequential(\n",
       "        (0): Conv3DNormed(320, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(320, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-7): 7 x Sequential(\n",
       "              (0): Dropout3d(p=0.2, inplace=False)\n",
       "              (1): Conv3DNormed(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3DNormed(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (mask_blocks): ModuleList(\n",
       "      (0): MaxPool3d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): MaxPool3d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): MaxPool3d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(5, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "        (1-7): 7 x Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ConvBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "        (1-7): 7 x Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): ConvBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "        (1-7): 7 x Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): ConvBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "        (1-7): 7 x Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): ConvBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "        (1-7): 7 x Sequential(\n",
       "          (0): Dropout3d(p=0.2, inplace=False)\n",
       "          (1): Conv3DNormed(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Conv3DNormed(1024, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "log_board = util.diagnostics.LogBoard('log_dir', 6005)\n",
    "log_board.launch()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = util.UNet3D(\n",
    "#     Conv3d=util.nn.Conv3DNormed,\n",
    "#     block_depth=8,\n",
    "#     dropout=0.2,\n",
    "# ).to(device)\n",
    "# model.load_state_dict(torch.load('./bin/models/unet3d.pt', map_location=device))\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "fine_patcher = util.Patcher(\n",
    "    util.UNet3D(\n",
    "        Conv3d=util.nn.Conv3DNormed,\n",
    "        block_depth=8,\n",
    "        dropout=0.2,\n",
    "    ),\n",
    "    layers = [5, 64, 128, 256, 512, 1024, 1],\n",
    "    Conv3d=util.nn.Conv3DNormed,\n",
    "    dropout=0.2,\n",
    "    depth=8,\n",
    ").to(device)\n",
    "fine_patcher.load_state_dict(torch.load('./bin/models/patcher.pt', map_location=device))\n",
    "fine_patcher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /train/kidney_2/images from cache\n",
      "Loading /train/kidney_2/labels from cache\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "test = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=0,\n",
    "    samples=[\n",
    "        \"/train/kidney_2\"\n",
    "        # \"/train/kidney_3_sparse\"\n",
    "    ]\n",
    ")\n",
    "valid_data = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice:  0.1882352977991104\n",
      "true_positives:  tensor(8., device='cuda:0')\n",
      "false_positives:  tensor(42., device='cuda:0')\n",
      "false_negatives:  tensor(27., device='cuda:0')\n",
      "Dice:  0.6639999747276306\n",
      "true_positives:  tensor(83., device='cuda:0')\n",
      "false_positives:  tensor(57., device='cuda:0')\n",
      "false_negatives:  tensor(27., device='cuda:0')\n",
      "Dice:  0.654275119304657\n",
      "true_positives:  tensor(88., device='cuda:0')\n",
      "false_positives:  tensor(59., device='cuda:0')\n",
      "false_negatives:  tensor(34., device='cuda:0')\n",
      "Dice:  0.0640350878238678\n",
      "true_positives:  tensor(146., device='cuda:0')\n",
      "false_positives:  tensor(4133., device='cuda:0')\n",
      "false_negatives:  tensor(135., device='cuda:0')\n",
      "Dice:  0.06378331035375595\n",
      "true_positives:  tensor(146., device='cuda:0')\n",
      "false_positives:  tensor(4151., device='cuda:0')\n",
      "false_negatives:  tensor(135., device='cuda:0')\n",
      "Dice:  0.26547175645828247\n",
      "true_positives:  tensor(785., device='cuda:0')\n",
      "false_positives:  tensor(4197., device='cuda:0')\n",
      "false_negatives:  tensor(147., device='cuda:0')\n",
      "Dice:  0.31011608242988586\n",
      "true_positives:  tensor(1122., device='cuda:0')\n",
      "false_positives:  tensor(4836., device='cuda:0')\n",
      "false_negatives:  tensor(156., device='cuda:0')\n",
      "Dice:  0.27598080039024353\n",
      "true_positives:  tensor(1122., device='cuda:0')\n",
      "false_positives:  tensor(5731., device='cuda:0')\n",
      "false_negatives:  tensor(156., device='cuda:0')\n",
      "Dice:  0.27365854382514954\n",
      "true_positives:  tensor(1122., device='cuda:0')\n",
      "false_positives:  tensor(5800., device='cuda:0')\n",
      "false_negatives:  tensor(156., device='cuda:0')\n",
      "Dice:  0.31063973903656006\n",
      "true_positives:  tensor(1362., device='cuda:0')\n",
      "false_positives:  tensor(5846., device='cuda:0')\n",
      "false_negatives:  tensor(199., device='cuda:0')\n",
      "Dice:  0.3122811019420624\n",
      "true_positives:  tensor(1382., device='cuda:0')\n",
      "false_positives:  tensor(5887., device='cuda:0')\n",
      "false_negatives:  tensor(200., device='cuda:0')\n",
      "Dice:  0.3121047914028168\n",
      "true_positives:  tensor(1382., device='cuda:0')\n",
      "false_positives:  tensor(5892., device='cuda:0')\n",
      "false_negatives:  tensor(200., device='cuda:0')\n",
      "Dice:  0.32436603307724\n",
      "true_positives:  tensor(1471., device='cuda:0')\n",
      "false_positives:  tensor(5924., device='cuda:0')\n",
      "false_negatives:  tensor(204., device='cuda:0')\n",
      "Dice:  0.32362955808639526\n",
      "true_positives:  tensor(1473., device='cuda:0')\n",
      "false_positives:  tensor(5952., device='cuda:0')\n",
      "false_negatives:  tensor(205., device='cuda:0')\n",
      "Dice:  0.32611989974975586\n",
      "true_positives:  tensor(1507., device='cuda:0')\n",
      "false_positives:  tensor(5978., device='cuda:0')\n",
      "false_negatives:  tensor(250., device='cuda:0')\n",
      "Dice:  0.3253103196620941\n",
      "true_positives:  tensor(1507., device='cuda:0')\n",
      "false_positives:  tensor(5998., device='cuda:0')\n",
      "false_negatives:  tensor(253., device='cuda:0')\n",
      "Dice:  0.3255663514137268\n",
      "true_positives:  tensor(1509., device='cuda:0')\n",
      "false_positives:  tensor(5999., device='cuda:0')\n",
      "false_negatives:  tensor(253., device='cuda:0')\n",
      "Dice:  0.2356739342212677\n",
      "true_positives:  tensor(1606., device='cuda:0')\n",
      "false_positives:  tensor(6057., device='cuda:0')\n",
      "false_negatives:  tensor(4360., device='cuda:0')\n",
      "Dice:  0.23660321533679962\n",
      "true_positives:  tensor(1616., device='cuda:0')\n",
      "false_positives:  tensor(6064., device='cuda:0')\n",
      "false_negatives:  tensor(4364., device='cuda:0')\n",
      "Dice:  0.23999418318271637\n",
      "true_positives:  tensor(1649., device='cuda:0')\n",
      "false_positives:  tensor(6064., device='cuda:0')\n",
      "false_negatives:  tensor(4380., device='cuda:0')\n",
      "Dice:  0.23379744589328766\n",
      "true_positives:  tensor(1654., device='cuda:0')\n",
      "false_positives:  tensor(6461., device='cuda:0')\n",
      "false_negatives:  tensor(4380., device='cuda:0')\n",
      "Dice:  0.4994126558303833\n",
      "true_positives:  tensor(5527., device='cuda:0')\n",
      "false_positives:  tensor(6600., device='cuda:0')\n",
      "false_negatives:  tensor(4480., device='cuda:0')\n",
      "Dice:  0.6035969257354736\n",
      "true_positives:  tensor(8575., device='cuda:0')\n",
      "false_positives:  tensor(6669., device='cuda:0')\n",
      "false_negatives:  tensor(4594., device='cuda:0')\n",
      "Dice:  0.6473560929298401\n",
      "true_positives:  tensor(10504., device='cuda:0')\n",
      "false_positives:  tensor(6780., device='cuda:0')\n",
      "false_negatives:  tensor(4664., device='cuda:0')\n",
      "Dice:  0.6472763419151306\n",
      "true_positives:  tensor(10504., device='cuda:0')\n",
      "false_positives:  tensor(6784., device='cuda:0')\n",
      "false_negatives:  tensor(4664., device='cuda:0')\n",
      "Dice:  0.6489534378051758\n",
      "true_positives:  tensor(10588., device='cuda:0')\n",
      "false_positives:  tensor(6790., device='cuda:0')\n",
      "false_negatives:  tensor(4665., device='cuda:0')\n",
      "Dice:  0.6483573913574219\n",
      "true_positives:  tensor(10588., device='cuda:0')\n",
      "false_positives:  tensor(6820., device='cuda:0')\n",
      "false_negatives:  tensor(4665., device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute output\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m p_y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.52\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# p_y[-1] += p_y[-1] * F.interpolate(p_y[-2] - 0.5, size=16, mode='nearest') * 0.5\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# p_y[-1] += F.interpolate(p_y[-3] - 0.5, size=16, mode='nearest') * 0.1\u001b[39;00m\n\u001b[1;32m     35\u001b[0m pred_masks \u001b[38;5;241m=\u001b[39m [(p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m p_y]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sennet-kaggle/src/exp2_small_net/../util/nn/unet3d.py:296\u001b[0m, in \u001b[0;36mPatcher.forward\u001b[0;34m(self, x, threshold)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 296\u001b[0m     p_y \u001b[38;5;241m=\u001b[39m [F\u001b[38;5;241m.\u001b[39msigmoid(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]] \u001b[38;5;66;03m# skip deepest mask\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m    299\u001b[0m         F\u001b[38;5;241m.\u001b[39minterpolate(p_y[\u001b[38;5;241m0\u001b[39m], scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    300\u001b[0m         F\u001b[38;5;241m.\u001b[39minterpolate(p_y[\u001b[38;5;241m1\u001b[39m], scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39m_prep_input(x)\n\u001b[1;32m    304\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    306\u001b[0m     prob_vessel \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(z)) \u001b[38;5;66;03m# (B, 1, 1, 1, 1)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sennet-kaggle/src/exp2_small_net/../util/nn/unet3d.py:241\u001b[0m, in \u001b[0;36mUNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_blocks))):\n\u001b[1;32m    240\u001b[0m     cross_input \u001b[38;5;241m=\u001b[39m down_agg[:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(up_agg)) \u001b[38;5;241m+\u001b[39m [down_agg[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m--> 241\u001b[0m     up_agg\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_input\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    244\u001b[0m     o(x)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_blocks, [down_agg[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m up_agg)\n\u001b[1;32m    246\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sennet-kaggle/src/exp2_small_net/../util/nn/unet3d.py:121\u001b[0m, in \u001b[0;36mUNetCrossBlock3D.forward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    119\u001b[0m zs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(xs)):\n\u001b[0;32m--> 121\u001b[0m     zs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_conv_block(torch\u001b[38;5;241m.\u001b[39mcat(zs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sennet-kaggle/src/exp2_small_net/../util/nn/unet3d.py:59\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 59\u001b[0m     zz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     z \u001b[38;5;241m=\u001b[39m zz\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nruns = 1000\n",
    "\n",
    "class AggDice(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.agg_intersection = 0\n",
    "        # self.agg_cardinality = 0\n",
    "\n",
    "        self.true_positives = 0\n",
    "        self.false_positives = 0\n",
    "        self.false_negatives = 0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # self.agg_intersection += (y_pred * y_true).sum()\n",
    "        # self.agg_cardinality += (y_pred + y_true).sum()\n",
    "        # return 2 * self.agg_intersection / self.agg_cardinality\n",
    "\n",
    "        self.true_positives += (y_pred * y_true).sum()\n",
    "        self.false_positives += (y_pred * (1 - y_true)).sum()\n",
    "        self.false_negatives += ((1 - y_pred) * y_true).sum()\n",
    "\n",
    "        return 2 * self.true_positives / (2 * self.true_positives + self.false_positives + self.false_negatives)\n",
    "\n",
    "dice_fn = AggDice()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(nruns):\n",
    "        x, y, _ = next(iter(valid_data))\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "        # Compute output\n",
    "        p_y = fine_patcher(x, threshold=0.51)\n",
    "        # p_y[-1] += p_y[-1] * F.interpolate(p_y[-2] - 0.5, size=16, mode='nearest') * 0.5\n",
    "        # p_y[-1] += F.interpolate(p_y[-3] - 0.5, size=16, mode='nearest') * 0.1\n",
    "        pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "        masks = fine_patcher.unet.deep_masks(y)\n",
    "\n",
    "        # p_y[-1] -= F.interpolate(((p_y[-2]) < 0.5).float() - 0.5, size=16, mode='nearest') * 0.1\n",
    "        p_y[-1] -= F.interpolate((p_y[-2] < 0.1).float(), size=16, mode='nearest') * \\\n",
    "             F.interpolate((p_y[-3] < 0.1).float(), size=16, mode='nearest') * \\\n",
    "            F.interpolate((p_y[-4] < 0.1).float(), size=16, mode='nearest') * 0.01\n",
    "        p_y[-1] += F.interpolate((p_y[-2] > 0.5).float(), size=16, mode='nearest') * \\\n",
    "             F.interpolate((p_y[-3] > 0.5).float(), size=16, mode='nearest') * \\\n",
    "            F.interpolate((p_y[-4] > 0.5).float(), size=16, mode='nearest') * 0.01\n",
    "        # p_y[-1] -= F.interpolate((p_y[-4] < 0.5).float(), size=16, mode='nearest') * 0.01\n",
    "\n",
    "        pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Dice: ', dice_fn(pred_masks[-1], masks[-1]).item())\n",
    "            print('true_positives: ', dice_fn.true_positives)# / (i + 1))\n",
    "            print('false_positives: ', dice_fn.false_positives)# / (i + 1))\n",
    "            print('false_negatives: ', dice_fn.false_negatives)# / (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 16, 16])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_masks[-1].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8762, device='cuda:0')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9683e-09, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84917330e78d4e3f841090b352e7f469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=15), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f670efd90d064d108f48a8d884645ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_td', max=15), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "print(util.DiceScore()(pred_masks[-1][i], masks[-1][i]))\n",
    "print(masks[-1][i].sum())\n",
    "util.Display(pred_masks[-1][i].squeeze().cpu())(), util.Display(x[i].cpu().squeeze(), masks[-1][i].squeeze().cpu())()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
