{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "log_board = util.diagnostics.LogBoard('log_dir', 6005)\n",
    "log_board.launch()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /train/kidney_1_dense/images from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0116 02:59:58.550872 140171716478144 program.py:298] TensorBoard could not bind to port 6005, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6005, it was already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /train/kidney_1_dense/labels from cache\n",
      "Loading /train/kidney_3_sparse/images from cache\n",
      "Loading /train/kidney_3_sparse/labels from cache\n",
      "Loading /train/kidney_2/images from cache\n",
      "Loading /train/kidney_2/labels from cache\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16\n",
    "train = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=0.5,\n",
    "    samples=[\n",
    "        \"/train/kidney_1_dense\",\n",
    "        \"/train/kidney_3_sparse\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "test = util.data.SenNet(\n",
    "    patch_size,\n",
    "    guarantee_vessel=0.1,\n",
    "    samples=[\n",
    "        \"/train/kidney_2\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_board.clear('train')\n",
    "log_board.clear('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# b = 22\n",
    "# x = torch.randn(b, 1, 16, 16).to(device)\n",
    "# probs = F.sigmoid(torch.randn(b, 1, 1, 1, 1)).to(device)\n",
    "\n",
    "# mask = (probs > 0.5).squeeze().unsqueeze(1)\n",
    "\n",
    "# mask.squeeze().unsqueeze(1).shape, mask.sum(), mask.squeeze(), x[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28408.28125, 28408.28125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.num_patches / 32, test.num_patches / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "save_every = 500\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "t_logger = log_board.get_logger('train')\n",
    "v_logger = log_board.get_logger('val')\n",
    "\n",
    "train_data = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_data = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Setup model\n",
    "unet = util.UNet3D(\n",
    "    Conv3d=util.nn.Conv3DNormed,\n",
    "    block_depth=8,\n",
    "    dropout=0.2,\n",
    ")\n",
    "# unet.load_state_dict(torch.load('./bin/models/unet3d2.pt', map_location=device))\n",
    "patcher = util.Patcher(\n",
    "    unet,\n",
    "    layers = [2, 64, 128, 256, 512, 1024, 1],\n",
    "    Conv3d=util.nn.Conv3DNormed,\n",
    "    dropout=0.2,\n",
    "    depth=8,\n",
    ").to(device)\n",
    "patcher.load_state_dict(torch.load('./bin/models/patcher.pt', map_location=device))\n",
    "patcher.train()\n",
    "# unet.requires_grad_(False)\n",
    "# unet.eval()\n",
    "\n",
    "# optimizer & loss\n",
    "optimizer = torch.optim.Adam(patcher.net.parameters(), lr=0.0002)\n",
    "dice_fn = util.DiceScore().to(device)\n",
    "focal_loss = util.BinaryFocalLoss(\n",
    "    alpha=0.5,\n",
    "    gamma=1.8,\n",
    ")\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Training\n",
    "\n",
    "step = 0\n",
    "t = time()\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y, _) in enumerate(train_data):\n",
    "            step += 1\n",
    "\n",
    "            # Prepare data\n",
    "            aug = util.PatchAugment().to(device)\n",
    "            x, y = aug(x.float().to(device)), aug(y.float().to(device))\n",
    "\n",
    "            \n",
    "            p_y = patcher(x, full_output=False)\n",
    "            pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "            masks = unet.deep_masks(y)\n",
    "\n",
    "            # Compute loss\n",
    "            dlayers = []\n",
    "            flyaers = [0]\n",
    "            dloss = torch.stack([\n",
    "                (1 - dice_fn(p_y[i], masks[i]))\n",
    "                for i in dlayers\n",
    "            ]) if len(dlayers) > 0 else torch.zeros(0)\n",
    "            floss = torch.stack([\n",
    "                focal_loss(p_y[i], masks[i])\n",
    "                for i in flyaers\n",
    "            ]) if len(flyaers) > 0 else torch.zeros(0)\n",
    "            loss = dloss.sum() * 0.1 + floss.sum()\n",
    "\n",
    "            # Step grad\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_value_(patcher.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Logging & validation\n",
    "            with torch.no_grad():\n",
    "                # log loss\n",
    "                loss_dict = { f'dice_{k}' : dloss[i] for i, k in enumerate(dlayers) }\n",
    "                loss_dict.update({ f'focal_{k}' : floss[i] for i, k in enumerate(flyaers) })\n",
    "                t_logger.add_scalars('loss', loss_dict, step)\n",
    "                \n",
    "                # performance\n",
    "                # accuracy = [torch.eq(pred, mask).float().mean() for pred, mask in zip(pred_masks, masks)]\n",
    "                # dice = [dice_fn(pred, mask) for pred, mask in zip(pred_masks[1:], masks[1:])]\n",
    "                # perf_dict = { f'acc_{i}' : acc for i, acc in enumerate(accuracy) }\n",
    "                # perf_dict.update({ f'dice_{i+1}' : d for i, d in enumerate(dice) })\n",
    "                # t_logger.add_scalars('performance', perf_dict, step)\n",
    "\n",
    "                # Performance logging\n",
    "                if (step + 1) % 10 == 0:\n",
    "                    # training performance\n",
    "                    sample_mask = pred_masks[0].squeeze().bool()\n",
    "                    pred_masks = [pred_masks[0]] + [torch.zeros_like(m) for m in masks[1:]]\n",
    "                    for i, p in enumerate(patcher.unet(x[sample_mask])):\n",
    "                        pred_masks[i + 1][sample_mask] = (p > 0.5).float()\n",
    "\n",
    "                    accuracy = [torch.eq(pred, mask).float().mean() for pred, mask in zip(pred_masks, masks)]\n",
    "                    dice = [dice_fn(pred, mask) for pred, mask in zip(pred_masks[1:], masks[1:])]\n",
    "                    perf_dict = { f'acc_{i}' : acc for i, acc in enumerate(accuracy) }\n",
    "                    perf_dict.update({ f'dice_{i+1}' : d for i, d in enumerate(dice) })\n",
    "                    t_logger.add_scalars('performance', perf_dict, step)\n",
    "\n",
    "                    # stats\n",
    "                    for i, (prob, pred, mask) in enumerate(zip(p_y, pred_masks, masks)):\n",
    "                        t_logger.add_scalars(f'stats_{i + 1}',{\n",
    "                            'prob_std': prob.std(),\n",
    "                            'prob_mean': prob.mean(),\n",
    "                            'pred_std': pred.std(),\n",
    "                            'pred_mean': pred.mean(),\n",
    "                            'mask_std': mask.std(),\n",
    "                            'mask_mean': mask.mean(),\n",
    "                        }, step)\n",
    "\n",
    "                    # validation performance\n",
    "                    patcher.eval()\n",
    "                    x, y, _ = next(iter(valid_data))\n",
    "                    x, y = x.float().to(device), y.float().to(device)\n",
    "                    \n",
    "                    p_y = patcher(x) # full output\n",
    "                    pred_masks = [(p > 0.5).float() for p in p_y]\n",
    "                    masks = unet.deep_masks(y)\n",
    "                    \n",
    "                    sample_mask = pred_masks[0].squeeze().bool()\n",
    "                    pred_masks = [pred_masks[0]] + [torch.zeros_like(m) for m in masks[1:]]\n",
    "                    for i, p in enumerate(patcher.unet(x[sample_mask])):\n",
    "                        pred_masks[i + 1][sample_mask] = (p > 0.5).float()\n",
    "\n",
    "                    accuracy = [torch.eq(pred, mask).float().mean() for pred, mask in zip(pred_masks, masks)]\n",
    "                    dice = [dice_fn(pred, mask) for pred, mask in zip(pred_masks[1:], masks[1:])]\n",
    "                    perf_dict = { f'acc_{i}' : acc for i, acc in enumerate(accuracy) }\n",
    "                    perf_dict.update({ f'dice_{i+1}' : d for i, d in enumerate(dice) })\n",
    "                    v_logger.add_scalars('performance', perf_dict, step)\n",
    "\n",
    "                    v_logger.add_image('masks', util.mask_plots(x, masks, pred_masks), step, dataformats='HWC')\n",
    "                    t_logger.add_scalar('time', time() - t, step)\n",
    "                    t = time()\n",
    "                    patcher.train()\n",
    "                \n",
    "                # Save model\n",
    "                if (step + 1) % save_every == 0:\n",
    "                    torch.save(patcher.state_dict(), f'./bin/models/patcherIN_PROGRESS.pt')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # torch.save(patcher.state_dict(), f'./bin/models/patcher.pt')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('./bin/models', exist_ok=True)\n",
    "\n",
    "torch.save(patcher.state_dict(), f'./bin/models/patcher.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m upsample \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m upsample(x)\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3903\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3901\u001b[0m         align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3903\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Number of spatial dimensions.\u001b[39;00m\n\u001b[1;32m   3905\u001b[0m \u001b[38;5;66;03m# Process size and scale_factor.  Validate that exactly one is set.\u001b[39;00m\n\u001b[1;32m   3906\u001b[0m \u001b[38;5;66;03m# Validate its length if it is a list, or expand it if it is a scalar.\u001b[39;00m\n\u001b[1;32m   3907\u001b[0m \u001b[38;5;66;03m# After this block, exactly one of output_size and scale_factors will\u001b[39;00m\n\u001b[1;32m   3908\u001b[0m \u001b[38;5;66;03m# be non-None, and it will be a list (or tuple).\u001b[39;00m\n\u001b[1;32m   3909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scale_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "upsample = F.interpolate\n",
    "x = torch.randn(1, 1, 4, 4, 4).to(device)\n",
    "upsample(x).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
